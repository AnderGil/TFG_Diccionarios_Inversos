# -*- coding: utf-8 -*-
"""Process dictionaries.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sWup6Q0Xl8R1QcCwk_Gp_4FzpBtkka0W
"""

from google.colab import drive
drive.mount("/content/drive")

import os

def findOccurrences(s, ch):
    return [i for i, letter in enumerate(s) if letter == ch]

def check_value(data, val):
    return any(i['word']==val for i in data)

#Process Wordnet_Train

folder2 = "/content/drive/MyDrive/TFG/Sentence-transformers/data/en/"
name = "unseen.json"
f2 = open(folder+name, "r")
data = json.load(f2)
f2.close()


data_directory = "/content/drive/MyDrive/TFG/Finetunning/data/wordnet.en"
save_path = "/content/drive/MyDrive/TFG/Finetunning/cleaned_data"
if not os.path.exists(save_path):
    os.makedirs(save_path)
file_name = "wordnet_train.txt"
complete_name = os.path.join(save_path, file_name)
new_f = open(complete_name, "w")


for filename in os.listdir(data_directory):
  if not filename.endswith(".es"):
    f = open(data_directory+"/"+filename, "r")
    print(filename)
    for line in f:
      str = line.split(' ', 1)[1]
      splits = str.split(':')
      def_word = splits[0]
      if "," in def_word:
        number_of_defs = def_word.split(",")
        def_word = number_of_defs[0]
      number_of_words = def_word.split(" ")
      if len(number_of_words)==1:
        if not check_value(data, def_word):
          def_sentence = splits[1]
          def_sentence = def_sentence.replace("\n", "")
          new_line = "The definition of " + def_word + " is:" + def_sentence

          new_f.write(new_line + "\n")
       
    f.close()
new_f.close()

#Process Wordnet_Eval_Corpus_Entero

data_directory = "/content/drive/MyDrive/TFG/Finetunning/data/wordnet.en"
save_path = "/content/drive/MyDrive/TFG/Finetunning/cleaned_data"
if not os.path.exists(save_path):
    os.makedirs(save_path)
file_name = "wordnet_dictionary.txt"
eval_file_name = "wordnet_eval.txt"
complete_name = os.path.join(save_path, file_name)
complete_eval_name = os.path.join(save_path, eval_file_name)
new_f = open(complete_name, "w")
eval_f = open(complete_eval_name, "w")


for filename in os.listdir(data_directory):
  if not filename.endswith(".es"):
    f = open(data_directory+"/"+filename, "r")
    print(filename)
    for line in f:
      str = line.split(' ', 1)[1]
      splits = str.split(':')
      def_word = splits[0]
      if "," in def_word:
        number_of_defs = def_word.split(",")
        def_word = number_of_defs[0]
      number_of_words = def_word.split(" ")
      if len(number_of_words)==1:
        def_sentence = splits[1]
        def_sentence = def_sentence.replace("\n", "")
        new_line = "The definition of " + def_word + " is:" + def_sentence

        new_f.write(new_line + "\n")
        eval_f.write(new_line + " ||| 3 " + "\n")
       
    f.close()
new_f.close()
eval_f.close()

#Process conjunto de datos comparable para evaluaciÃ³n


import json

folder2 = "/content/drive/MyDrive/TFG/Sentence-transformers/data/en/"
files = ["seen.json", "unseen.json", "desc.json"]

new_folder = "/content/drive/MyDrive/TFG/Finetunning/cleaned_data"
for file in files:
  f = open(folder+file, "r")
  eval_file = open(new_folder+file[:-4] + "_eval.txt", "w")
  data = json.load(f)

  cont2 = 0
  for i in data:
    cont2 += 1
    new_line = "The definition of " + i['word'] + " is: " + i['definitions'] + " ||| 3"
    
    eval_file.write(new_line + "\n")
  eval_file.close()

#Process def.txt

file_directory = "/content/drive/MyDrive/TFG/Finetunning/data/def.text"
save_path = "/content/drive/MyDrive/TFG/Finetunning/cleaned_data"
if not os.path.exists(save_path):
    os.makedirs(save_path)
file_name = "def_dictionary.txt"
eval_file_name = "def_1000_eval.txt"
complete_name = os.path.join(save_path, file_name)
complete_eval_name = os.path.join(save_path, eval_file_name)
new_f = open(complete_name, "w")
eval_f = open(complete_eval_name, "w")

f = open(file_directory, "r")
cont = 0
definitions = 0
for line in f:
  if cont >= 665:
    indexes = findOccurrences(line, '"')

    def_word = line[indexes[0]+1:indexes[1]]
    definition = line[indexes[2]+1:indexes[3]]
    splited_line = line.split()
    if def_word in splited_line:
      def_index = splited_line.index(def_word)
      new_line = "The definition of " + def_word + " is: " + definition + "."
      new_f.write(new_line + "\n")
      eval_f.write(new_line + " ||| 3\n")
      definitions += 1
      if definitions == 1000:
        break
  else: 
    cont +=1

f.close()
new_f.close()
eval_f.close()

#Process cobuild

file_directory = "/content/drive/MyDrive/TFG/Finetunning/data/cobuild.dict"
save_path = "/content/drive/MyDrive/TFG/Finetunning/cleaned_data"
if not os.path.exists(save_path):
    os.makedirs(save_path)
file_name = "cobuild_dictionary.txt"
eval_file_name = "cobuild_eval.txt"
complete_f_name = os.path.join(save_path, file_name)
complete_eval_name = os.path.join(save_path, eval_file_name)
new_f = open(complete_f_name, "w")
eval_f = open(complete_eval_name, "w")

f = open(file_directory, "r")
cont = 0
for line in f:
  if "[DEF]" in line:
    line = line[5:]
    begin_index = line.index("]")
    end_index = line.index("/")
    def_word = line[begin_index+1:end_index-1]
    word_def_index = begin_index + 1
    line = line.replace("[CIT]", "")
    line = line.replace("[/CIT]", "")
    line = line.replace("[ALT]", "")
    line = line.replace("[/ALT]", "")
    line = line.replace("[CIF]", "")
    line = line.replace("[/CIF]", "")
    line = line.replace("\n", "")

    splited_line = line.split()
    if def_word in splited_line:
      def_index = splited_line.index(def_word)
      new_f.write(line + "\n")
      eval_f.write(line + " ||| " + str(def_index) + "\n")
f.close()
new_f.close()
eval_f.close()

#Process ldoce
file_directory = "/content/drive/MyDrive/TFG/Finetunning/data/ldoce.dict"
save_path = "/content/drive/MyDrive/TFG/Finetunning/cleaned_data"
if not os.path.exists(save_path):
    os.makedirs(save_path)
file_name = "ldoce_dictionary.txt"
eval_file_name = "ldoce_1000_eval.txt"
complete_f_name = os.path.join(save_path, file_name)
complete_eval_name = os.path.join(save_path, eval_file_name)
new_f = open(complete_f_name, "w")
eval_f = open(complete_eval_name, "w")

f = open(file_directory, "r", encoding="latin-1")
cont = 0
definitions = 0
for line in f:
  if cont >= 433:
    indexes = findOccurrences(line, "|")
    def_word = line[:indexes[0]-4]
    while def_word.endswith('-') or def_word.endswith('_') or def_word.endswith('.'):
      def_word = def_word[:-1]
    definition = line[indexes[len(indexes)-3]+1:indexes[len(indexes)-2]]
    new_line = "The definition of " + def_word + " is: " + definition + "."
    new_line.replace("\n", "")
    new_f.write(new_line + "\n")
    eval_f.write(new_line + " ||| 3\n")
    definitions += 1
    if definitions== 1000:
      break
  else:
    cont += 1

f.close()
new_f.close()
eval_f.close()